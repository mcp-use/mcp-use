---
title: "OpenAI"
description: "Use MCP-USE tools directly with the OpenAI SDK"
icon: "cubes"
---

# Using MCP-USE with OpenAI

The OpenAI adapter allows you to seamlessly integrate tools from any MCP server with the OpenAI Python SDK. This enables you to use `mcp-use` as a tool provider for your OpenAI-powered agents.

## How it Works

The `OpenAIMCPAdapter` converts tools from your active MCP servers into a format compatible with OpenAI's tool-calling feature. It also provides a mapping to execute these tools when requested by the OpenAI model.

## Usage

Here's how to use the adapter to provide tools to an OpenAI Chat Completion:

<CodeGroup>
  ```python
  import asyncio

  from dotenv import load_dotenv
  from openai import OpenAI
  
  from mcp_use import MCPClient
  from mcp_use.adapters import OpenAIMCPAdapter
  
  # This example demonstrates how to use our integration
  # adapaters to use MCP tools and convert to the right format.
  # In particularly, this example uses the OpenAIMCPAdapter.
  
  load_dotenv()
  
  
  async def main():
      config = {
          "mcpServers": {
              "airbnb": {"command": "npx", "args": ["-y", "@openbnb/mcp-server-airbnb", "--ignore-robots-txt"]}
          }
      }
  
      try:
          client = MCPClient(config=config)
  
          # Creates the adapter for OpenAI's format
          adapter = OpenAIMCPAdapter()
  
          # Convert tools from active connectors to the OpenAI's format
          openai_tools = await adapter.create_tools(client)
  
          # Use tools with OpenAI's SDK (not agent in this case)
          openai = OpenAI()
          input_list = [{"role": "user", "content": "Search on Airbnb the cheapest hotel in Trapani for two nights."}]
          response = openai.chat.completions.create(model="gpt-4o", messages=input_list, tools=openai_tools)
  
          response_message = response.choices[0].message
          input_list.append(response_message)
          if not response_message.tool_calls:
              print("No tool call requested by the model")
              print(response_message.content)
              return
  
          for tool_call in response_message.tool_calls:
              import json
  
              function_name = tool_call.function.name
              arguments = json.loads(tool_call.function.arguments)
  
              # Use the adapter's map to get the correct connector
              connector = adapter.tool_to_connector_map[function_name]
  
              print(f"Executing tool: {function_name}({arguments})")
              tool_result = await connector.call_tool(name=function_name, arguments=arguments)
  
          # Handle and print the result
          if getattr(tool_result, "isError", False):
              print(f"Error: {tool_result.content}")
              return
  
          input_list.append(
              {"tool_call_id": tool_call.id, "role": "tool", "name": function_name, "content": tool_result.content}
          )
  
          # Send the tool result back to the model
          second_response = openai.chat.completions.create(model="gpt-4o", messages=input_list, tools=openai_tools)
          final_message = second_response.choices[0].message
          print("\n--- Final response from the model ---")
          print(final_message.content)
  
      except Exception as e:
          print(f"Error: {e}")
  
  
  if __name__ == "__main__":
      asyncio.run(main())
  ```
</CodeGroup>

### Key Steps:
1.  **Initialize `MCPClient`**: Set up your MCP servers as usual.
2.  **Create `OpenAIMCPAdapter`**: Instantiate the adapter.
3.  **Generate Tools**: Use `adapter.create_tools(client)` to get a list of OpenAI-compatible tools.
4.  **Make API Call**: Pass the generated `openai_tools` to the `tools` parameter of `openai.chat.completions.create`.
5.  **Execute Tool Calls**: When the model returns `tool_calls`, use the `adapter.tool_to_connector_map` to find the correct `connector` for each tool and execute it with `connector.call_tool()`.
6.  **Return Results**: Send the tool execution results back to the model to get a final response.
